{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe1 in position 9: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Open the text file\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mData/BONUS_HASAM_202206235.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m----> 3\u001b[0m     lines_35 \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49mreadlines()\n\u001b[0;32m      5\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mData/BONUS_HASAM_202206233.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      6\u001b[0m     lines_33 \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mreadlines()\n",
      "File \u001b[1;32mc:\\Users\\yoave\\Anaconda3\\lib\\codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    320\u001b[0m     \u001b[39m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[1;32m--> 322\u001b[0m     (result, consumed) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer_decode(data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors, final)\n\u001b[0;32m    323\u001b[0m     \u001b[39m# keep undecoded input until the next call\u001b[39;00m\n\u001b[0;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m=\u001b[39m data[consumed:]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe1 in position 9: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# Open the text file\n",
    "with open('Data/BONUS_HASAM_202206235.txt', 'r') as f:\n",
    "    lines_35 = f.readlines()\n",
    "\n",
    "with open('Data/BONUS_HASAM_202206233.txt', 'r') as f:\n",
    "    lines_33 = f.readlines()\n",
    "\n",
    "lines = lines_35 + lines_33\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Structure\n",
    "## id = 9, fullname = 32, birth_date = 8, year = 4, zihui = 2, sug_isuk = 10, oved_dummy = 12,\n",
    "## wage = 10, employer_name = 32, tik_nikui = 9, sug_divuh = 1, anaf_calcali = 4\n",
    "\n",
    "# Create an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate over the lines of the file\n",
    "for line in lines:\n",
    "    # Extract the first 10 characters and assign to id\n",
    "    id = line[:9]\n",
    "    full_name = line[9:41][::-1]\n",
    "    birth_date = line[41:49]\n",
    "    year = line[49:53]\n",
    "    zihui = line[53:54]\n",
    "    sug_isuk = line[54:64][::-1]\n",
    "    oved_dummy = line[64:76][::-1]\n",
    "    wage = line[76:86]\n",
    "    employer_name = line[86:118][::-1]\n",
    "    tik_nikui = line[118:127]\n",
    "    sug_divuh = line[127:128]\n",
    "\n",
    "    ## Append the data to the data list\n",
    "    data.append((id, full_name, birth_date,\n",
    "                 year, zihui, sug_isuk, oved_dummy,\n",
    "                 wage, employer_name,\n",
    "                 tik_nikui, sug_divuh))\n",
    "\n",
    "# Create a data frame from the data list\n",
    "df = pd.DataFrame(data, columns=['id', 'full_name', 'birth_date', 'year', 'zihui', 'sug_isuk', 'oved_dummy', 'wage', 'employer_name', 'tik_nikui', 'sug_divuh'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter out strings with non numeric characters in the wage column like \"000000006K\"\n",
    "\n",
    "def filter_non_numeric_rows(column):\n",
    "    return [val for val in column if bool(re.search(r'[^\\d]', val))]\n",
    "    \n",
    "alphabet_list = list(filter_non_numeric_rows(df['wage']))\n",
    "\n",
    "df = df[~df['wage'].isin(alphabet_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Types\n",
    "\n",
    "## dtypes dict\n",
    "dtypes = {'id': str,\n",
    "          'full_name': str,\n",
    "          'zihui':object,\n",
    "          'sug_isuk': object,\n",
    "          'oved_dummy': str,\n",
    "          'wage': float,\n",
    "          'employer_name': str,\n",
    "          'tik_nikui': int,\n",
    "          'sug_divuh': object,\n",
    "          }\n",
    "\n",
    "df = df.astype(dtypes)\n",
    "\n",
    "## year to datetime\n",
    "#df[\"year\"] = pd.to_datetime(df[\"year\"], format='%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"wage\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duumies for employment months\n",
    "\n",
    "## Replace כ with 1\n",
    "df[\"oved_dummy\"]= df[\"oved_dummy\"].str.replace('כ', '1')\n",
    "df[\"oved_dummy\"]= df[\"oved_dummy\"].str.replace(' ', '0')\n",
    "\n",
    "\n",
    "month_cols = [\"drop1\",\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\",\"drop2\"]\n",
    "\n",
    "## Split every character in df[\"oved_dummie\"] to a new column\n",
    "df[month_cols] = df[\"oved_dummy\"].str.split(\"\",expand=True)\n",
    "\n",
    "## Drop the first and last columns\n",
    "df = df.drop(columns=[\"drop1\",\"drop2\"])\n",
    "## Drop from month_cols\n",
    "month_cols = month_cols[1:-1]\n",
    "\n",
    "for col in month_cols:\n",
    "    ## Replace \"\" with NaN\n",
    "    df[col] = df[col].replace('', 0)\n",
    "    df[col] = df[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "כ    1.0\n",
      "Name: zihui, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Drop non identified id's\n",
    "print(df[\"zihui\"].value_counts(normalize=True))\n",
    "df = df.loc[(df[\"zihui\"] != \"ל\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add a variable for mean monthly wage\n",
    "month_cols = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"]\n",
    "df[\"month_worked\"] = df[month_cols].sum(axis=1)\n",
    "df[\"mean_wage\"] = (df[\"wage\"]/df[\"month_worked\"]).round(2)\n",
    "\n",
    "for col in month_cols:\n",
    "    df[col] = df[col]*df[\"mean_wage\"]\n",
    "\n",
    "    ## Group by year\n",
    "df = df.groupby([\"id\",\"year\"]).agg({\"wage\":\"sum\",\"1\": \"sum\",\"2\":\"sum\",\"3\":\"sum\",\"4\":\"sum\",\"5\":\"sum\",\"6\":\"sum\",\"7\":\"sum\",\"8\":\"sum\",\"9\":\"sum\",\"10\":\"sum\",\"11\":\"sum\",\"12\":\"sum\"}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshape the data to long format (every month is a row for each id)\n",
    "df = df.melt(id_vars=[\"id\",\"year\"], \n",
    "             value_vars=[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"], \n",
    "             var_name=\"month\", \n",
    "             value_name=\"wage_per_month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To datetime format\n",
    "df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'], format='%Y-%m')\n",
    "df = df.drop(columns=[\"month\",\"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save To CSV format\n",
    "df.to_csv(\"Output/BONUS_HASAM_202206233_35.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21285703334ff9ad0485a20549414d39509d302abdef938bdec846b879f92609"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
